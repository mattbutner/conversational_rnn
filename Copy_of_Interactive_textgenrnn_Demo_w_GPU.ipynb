{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Interactive textgenrnn Demo w/ GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattbutner/conversational_rnn/blob/master/Copy_of_Interactive_textgenrnn_Demo_w_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  Interactive textgenrnn Demo w/ GPU\n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: December 2nd, 2018*\n",
        "\n",
        "Generate text using a pretrained neural network with a few lines of code, or easily train your own text-generating neural network of any size and complexity, **for free on a GPU using Collaboratory!**\n",
        "\n",
        "For more about textgenrnn, you can visit [this GitHub repository](https://github.com/minimaxir/textgenrnn).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes.\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "outputId": "e0e6b3d8-b399-4766-8c1b-94c3d74ab522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set the textgenrnn model configuration here: the default parameters here give good results for most workflows. (see the [demo notebook](https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) for more information about these parameters)\n",
        "\n",
        "If you are using an input file where documents are line-delimited, make sure to set `line_delimited` to `True`."
      ]
    },
    {
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_cfg = {\n",
        "    'word_level': True,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 5,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 100,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': True,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 30,   # set higher to train the model for longer\n",
        "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BT__brhBCvJu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any text file** and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_name = \"mat_2_neil.txt\"\n",
        "model_name = 'colaboratory'   # change to set file name of resulting trained models/texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The next cell will start the actual training. And thanks to the power of Keras's CuDNN layers, training is super-fast when compared to CPU training on a local machine!\n",
        "\n",
        "Ideally, you want a training loss less than `1.0` in order for the model to create sensible text consistently."
      ]
    },
    {
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "outputId": "d8013a67-d17e-419b-f73d-f93d4de00b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3862
        }
      },
      "cell_type": "code",
      "source": [
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3,245 texts collected.\n",
            "Training new model w/ 3-layer, 128-cell LSTMs\n",
            "Training on 42,131 word sequences.\n",
            "Epoch 1/30\n",
            "41/41 [==============================] - 3s 78ms/step - loss: 6.1664\n",
            "Epoch 2/30\n",
            "41/41 [==============================] - 2s 58ms/step - loss: 5.6197\n",
            "Epoch 3/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 5.4102\n",
            "Epoch 4/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 4.9199\n",
            "Epoch 5/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 4.3964\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "i ' m not sure . i ' m not sure . i ' m not sure it was a . . i ' m at the the s the the program ?\n",
            "\n",
            "i ' m at the the ll , the the the before and friday\n",
            "\n",
            "i think it ' s a a a s ?\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "i think it ' s a a a s\n",
            "\n",
            "i ' m at the the d and you could talk go\n",
            "\n",
            "i ' m not sure if you want to talk to you talk later ?\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "\n",
            "\n",
            "okay let me ! want to you home talk later ?\n",
            "\n",
            "hope you ' re so great !\n",
            "\n",
            "Epoch 6/30\n",
            "41/41 [==============================] - 2s 52ms/step - loss: 3.9556\n",
            "Epoch 7/30\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 3.5505\n",
            "Epoch 8/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 3.1598\n",
            "Epoch 9/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 2.8052\n",
            "Epoch 10/30\n",
            "41/41 [==============================] - 3s 66ms/step - loss: 2.4966\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "i ' m not sure i ' m reading\n",
            "\n",
            "i ' m not sure i ' m not sure i ' m not sure i ' ll let you know if you want to talk about it later though . i ' m not sure i ' m on the cell phone lot\n",
            "\n",
            "i ' m not sure i ' m not sure i ' m not sure what i ' m about it . i ' m not sure i ' m not sure if you want to do it or the tram ?\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "i think i ' m going to bed , want to go for a bit . i think i am not sure . i think i ' m going to bed neil .\n",
            "\n",
            "i ' m going to bed . i ' m gonna hit it . are you too much neil !\n",
            "\n",
            "i ' m not sure i ' m going to bed .\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "that ' s so great !\n",
            "\n",
            "totally i might be getting . will 2 than 100 + . seattle . no i ' ve been old ! i hope you have a great day with we are being times my sister designs looks loss , but i bet we were kind of , going for you deserve the next week i is the email i comes !\n",
            "\n",
            "haha hey it ' s !\n",
            "\n",
            "Epoch 11/30\n",
            "41/41 [==============================] - 2s 53ms/step - loss: 2.2370\n",
            "Epoch 12/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 2.0293\n",
            "Epoch 13/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 1.8481\n",
            "Epoch 14/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 1.6962\n",
            "Epoch 15/30\n",
            "41/41 [==============================] - 3s 66ms/step - loss: 1.5605\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "i think i ' m going to bed . i ' m not sure what you are .\n",
            "\n",
            "i think i ' m going to bed . i ' m going to bed . i ' m not sure what you are .\n",
            "\n",
            "i ' m not sure what you are .\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "i think you can buy tickets for the manufacturer .\n",
            "\n",
            "i ' m not sure how it was social\n",
            "\n",
            "i think i can floss that , but i can watch them\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "and i wonder you ' t rush for an bus\n",
            "\n",
            "absolutely , i saw your into that and it ' s a money landscape , they are the twice by didn ' t head her .\n",
            "\n",
            "nice are the mountain the your getting ago sachs we had to try finish doing a while or other morning in baby\n",
            "\n",
            "Epoch 16/30\n",
            "41/41 [==============================] - 2s 57ms/step - loss: 1.4453\n",
            "Epoch 17/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 1.3489\n",
            "Epoch 18/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 1.2600\n",
            "Epoch 19/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 1.1840\n",
            "Epoch 20/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 1.1169\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "i ' m not sure i know what you ' ll make a bit more before than a bit .\n",
            "\n",
            "i ' m not sure how social they are .\n",
            "\n",
            "i ' m not sure about tera melos , i ' m so excited to see you neil !\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "i think they contract that stuff . are you all the hill : )\n",
            "\n",
            "i ' m not sure . i think you ' ll be back to eat i think . it ' s cool . you don ' t have to worry about parentheses matching but it introduces many about frustrations up friend\n",
            "\n",
            "hey i ' m done , did you make the best ! you ' ve been so amazing ! i hope you have a great day today\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "actually i ' m not sure how social this morning\n",
            "\n",
            "did you get solid maps or anything i ' d enjoy happy neil , you made our solid . been sure . i ' d be thinking to do it go ! i have you just some away today ? i ' ll only a second before you ' s nice about right now . neil is cool meeting neil !\n",
            "\n",
            "not super sure ! you ' ll check it of the days\n",
            "\n",
            "Epoch 21/30\n",
            "41/41 [==============================] - 2s 54ms/step - loss: 1.0604\n",
            "Epoch 22/30\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 1.0101\n",
            "Epoch 23/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 0.9675\n",
            "Epoch 24/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 0.9296\n",
            "Epoch 25/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 0.8961\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "i think it ' s okay .\n",
            "\n",
            "i think it would be four to be more than dinner !\n",
            "\n",
            "i ' m not sure about tera melos , how ' s your day going ?\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "hey neil , how ' s your day going ?\n",
            "\n",
            "you are so great !\n",
            "\n",
            "nice ! i ' m sure there ' s a instrument , but like a or first\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "thanks ! see you all your !\n",
            "\n",
            "hey any day am so i ' d getting into it off to we were you think it ' s gone . asked looks like no *\n",
            "\n",
            "oh good . are you to go . want to write too . i hope you have a great day .\n",
            "\n",
            "Epoch 26/30\n",
            "41/41 [==============================] - 2s 61ms/step - loss: 0.8686\n",
            "Epoch 27/30\n",
            "41/41 [==============================] - 3s 74ms/step - loss: 0.8453\n",
            "Epoch 28/30\n",
            "41/41 [==============================] - 3s 75ms/step - loss: 0.8242\n",
            "Epoch 29/30\n",
            "41/41 [==============================] - 3s 74ms/step - loss: 0.8079\n",
            "Epoch 30/30\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 0.7939\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "i think it would be so cool to work ! just wanted to make the move you have been picture today ?\n",
            "\n",
            "i ' m not sure how social they are .\n",
            "\n",
            "i think it is a good milk substitute , but super water intensive\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "i can ' t wait to see you soon !\n",
            "\n",
            "hey i ' m walking to innisfree\n",
            "\n",
            "thanks for understanding !\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "good running .\n",
            "\n",
            "okay i thought it ' ' ll be fun !\n",
            "\n",
            "in the department , i like a marathons one\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RTa6zf3e_9gV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can download a large amount of generated text from your model with the cell below! Rerun the cell as many times as you want for even more text!"
      ]
    },
    {
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
        "# changing the temperature schedule can result in wildly different output!\n",
        "temperature = [1.0, 0.5, 0.2, 0.2]   \n",
        "prefix = None   # if you want each generated text to start with a given seed text\n",
        "\n",
        "if train_cfg['line_delimited']:\n",
        "  n = 1000\n",
        "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "else:\n",
        "  n = 1\n",
        "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
        "\n",
        "textgen.generate_to_file(gen_file,\n",
        "                         temperature=temperature,\n",
        "                         prefix=prefix,\n",
        "                         n=n,\n",
        "                         max_gen_length=max_gen_length)\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ClJwpF_ACONp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can download the weights and configuration files in the cell below, allowing you recreate the model on your own computer!"
      ]
    },
    {
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oF4-PqF0Fl7R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To recreate the model on your own computer, after installing textgenrnn and TensorFlow, you can create a Python script with:\n",
        "\n",
        "```\n",
        "from textgenrnn import textgenrnn\n",
        "textgen = textgenrnn(weights_path='colaboratory_weights.hdf5',\n",
        "                       vocab_path='colaboratory_vocab.json',\n",
        "                       config_path='colaboratory_config.json')\n",
        "                       \n",
        "textgen.generate_samples(max_gen_length=1000)\n",
        "textgen.generate_to_file('textgenrnn_texts.txt', max_gen_length=1000)\n",
        "```\n",
        "\n",
        "Have fun with your new model! :)"
      ]
    },
    {
      "metadata": {
        "id": "92Zjtsb_Dgj-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Etcetera\n",
        "\n",
        "If the model fails to load on a local machine due to a model-size-not-matching bug (common in >30MB weights), this is due to a file export bug from Colaboratory. To work around this issue, save the weights to Google Drive with the two cells below and download from there."
      ]
    },
    {
      "metadata": {
        "id": "F-IzscxUHmAB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WR4_XJpfKAIn",
        "colab_type": "code",
        "outputId": "f70ce499-1062-4968-8423-c7dbcd71cc5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = drive.CreateFile({'title': '{}_weights.hdf5'.format(model_name)})\n",
        "uploaded.SetContentFile('{}_weights.hdf5'.format(model_name))\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1b6T6M32YnXs-c0NB-PEi6MhAdCuG7RHy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ig-KVgkCDCKD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "metadata": {
        "id": "rIHiVP53FnsX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}